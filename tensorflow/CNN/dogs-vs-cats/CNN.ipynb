{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25002\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "print(len(os.listdir(f'{os.getcwd()}/dogs-vs-cats/train/train')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats_dir : 12500\n",
      "dogs_dir : 12500\n"
     ]
    }
   ],
   "source": [
    "fromDIR = f'{os.getcwd()}/dogs-vs-cats/train/train'\n",
    "files = [i for i in os.listdir(f'{os.getcwd()}/dogs-vs-cats/train/train')]\n",
    "for file in files:\n",
    "    if 'cat.' in file:\n",
    "        copyfile(os.path.join(fromDIR, file),os.path.join(fromDIR+'/cats/',file))\n",
    "    elif 'dog.' in file:\n",
    "        copyfile(os.path.join(fromDIR,file),os.path.join(fromDIR+'/dogs/',file))\n",
    "print('cats_dir :',len(os.listdir(fromDIR+'/cats')))\n",
    "print('dogs_dir :', len(os.listdir(fromDIR+'/dogs')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats_dir_t : 10000\n",
      "dogs_dir_t : 10000\n",
      "cats_dir_v : 2500\n",
      "dogs_dir_V : 2500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "d_files = [i for i in os.listdir(fromDIR+'/dogs/')]\n",
    "c_files = [i for i in os.listdir(fromDIR+'/cats/')]\n",
    "d_files = random.sample(d_files, len(d_files))\n",
    "c_files = random.sample(c_files, len(c_files))\n",
    "toDIR_t = f'{os.getcwd()}/dogs-vs-cats/train/training/'\n",
    "toDIR_v = f'{os.getcwd()}/dogs-vs-cats/train/validation/'\n",
    "index = int(0.8 * len(os.listdir(fromDIR+'/cats')))\n",
    "for file in d_files[:index]:\n",
    "    copyfile(os.path.join(fromDIR+'/dogs/', file),os.path.join(toDIR_t+'dogs/',file))\n",
    "for file in c_files[:index]:\n",
    "    copyfile(os.path.join(fromDIR+'/cats/',file),os.path.join(toDIR_t+'cats/',file))\n",
    "for file in d_files[index:]:\n",
    "    copyfile(os.path.join(fromDIR+'/dogs/', file),os.path.join(toDIR_v+'dogs/',file))\n",
    "for file in c_files[index:]:\n",
    "    copyfile(os.path.join(fromDIR+'/cats/',file),os.path.join(toDIR_v+'cats/',file))\n",
    "print('cats_dir_t :',len(os.listdir(toDIR_t+'/cats')))\n",
    "print('dogs_dir_t :', len(os.listdir(toDIR_t+'/dogs')))\n",
    "print('cats_dir_v :',len(os.listdir(toDIR_v+'/cats')))\n",
    "print('dogs_dir_V :', len(os.listdir(toDIR_v+'/dogs')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAINING_DIR = toDIR_t\n",
    "train_datagen = ImageDataGenerator(rescale= 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "TRAINING_DIR,batch_size =10,class_mode ='binary', target_size=(150,150)) \n",
    "\n",
    "VALIDATION_DIR =  toDIR_v\n",
    "validation_datagen =ImageDataGenerator(rescale= 1./255) \n",
    "\n",
    "validation_generator =validation_datagen.flow_from_directory(\n",
    "VALIDATION_DIR,batch_size =10,class_mode ='binary', target_size=(150,150)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape =(150,150,3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2000 steps, validate for 500 steps\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 448s 224ms/step - loss: 0.4805 - acc: 0.7778 - val_loss: 0.5017 - val_acc: 0.7536\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 461s 231ms/step - loss: 0.4243 - acc: 0.8119 - val_loss: 0.3797 - val_acc: 0.8352\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 419s 209ms/step - loss: 0.3960 - acc: 0.8302 - val_loss: 0.3720 - val_acc: 0.8332\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 403s 201ms/step - loss: 0.3725 - acc: 0.8419 - val_loss: 0.3427 - val_acc: 0.8520\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 444s 222ms/step - loss: 0.3615 - acc: 0.8512 - val_loss: 0.4681 - val_acc: 0.8246\n"
     ]
    }
   ],
   "source": [
    "class Mycallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('acc') >= 0.85:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = Mycallback()\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=10,\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator,\n",
    "                             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_dir = 'C:\\\\Users\\\\jye12\\\\GItBig\\\\tensorflow\\\\CNN\\\\dogs-vs-cats\\\\testing'\n",
    "test_filenames = os.listdir(test_dir+'/test1')\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]\n",
    "nb_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,class_mode=None,\n",
    "                                                  batch_size =10, target_size=(150,150),\n",
    "                                                  shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(test_generator, steps=nb_samples/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_df['category'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half(x):\n",
    "    if x >= .5:\n",
    "        x = 'dog'\n",
    "    else:\n",
    "        x = 'cat'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['category'] = test_df['category'].map(half) \n",
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20a2807d688>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_df.copy()\n",
    "submission_df['id'] = submission_df['filename'].str.split('.').str[0]\n",
    "submission_df['label'] = submission_df['category']\n",
    "submission_df.drop(['filename', 'category'], axis=1, inplace=True)\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
