{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## week 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
    "\n",
    "So, imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k etc.\n",
    "\n",
    "How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc.\n",
    "\n",
    "Hint: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands' etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: house_model\n",
    "def house_model(y_new):\n",
    "    xs = np.array([1., 2., 3., 4., 5., 6., 8.,])\n",
    "    ys = np.array([1., 1.5, 2., 2.5, 3., 3.5, 4.5])\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(1, input_shape = [1])])\n",
    "    model.compile(optimizer = 'SGD', loss = 'mse')\n",
    "    model.fit(xs,ys, epochs =20)\n",
    "    return model.predict(y_new)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7 samples\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 28ms/sample - loss: 29.2372\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 138us/sample - loss: 8.5858\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 285us/sample - loss: 2.5306\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 285us/sample - loss: 0.7550\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 143us/sample - loss: 0.2343\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 285us/sample - loss: 0.0815\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 285us/sample - loss: 0.0366\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 285us/sample - loss: 0.0233\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 146us/sample - loss: 0.0193\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 142us/sample - loss: 0.0180\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 287us/sample - loss: 0.0175\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 283us/sample - loss: 0.0173\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 289us/sample - loss: 0.0171\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 143us/sample - loss: 0.0169\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 285us/sample - loss: 0.0168\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 285us/sample - loss: 0.0166\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 142us/sample - loss: 0.0165\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 143us/sample - loss: 0.0164\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 143us/sample - loss: 0.0162\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 142us/sample - loss: 0.0161\n",
      "[4.0858464]\n"
     ]
    }
   ],
   "source": [
    "prediction = house_model([7.0])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2255 - accuracy: 0.9350\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0917 - accuracy: 0.9727\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0607 - accuracy: 0.9818\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0427 - accuracy: 0.9872\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0321 - accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], 0.9900333)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    class Mycallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self,epcoh, logs ={}):\n",
    "            if logs.get('accuracy') >= 0.99:\n",
    "                self.model.stop_training= True\n",
    "                \n",
    "    callbacks =Mycallback()\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test /255.0\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # YOUR CODE SHOULD START HERE\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256 , activation = 'relu'),\n",
    "        tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs = 10 ,callbacks =[callbacks]\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['accuracy'][-1]\n",
    "\n",
    "\n",
    "train_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## week 3\n",
    "### CNN\n",
    "#### Convolutions and MaxPooling\n",
    "\n",
    "```\n",
    "tf.keras.layers.Conv2D(64, (3,3) ,activation= 'relu', input_shape = (28,28,1)\n",
    "↓↓↓↓\n",
    "(None, 26, 26 ,64)\n",
    "Why? kerneal_size가 3 by 3 이기 때문에 28 by 28의 상하좌우 끝 열은 사용될 수 없다.(3by3의 중심이 될 수 없으므로) \n",
    "tf.keras.layers.MaxPooling2D(2,2)\n",
    "↓↓↓↓\n",
    "(None, 13, 13 ,64)\n",
    "Why? 2by2 격자를 하나로 간주하여 그중 가장 큰 값을 반환하여 26by26이 13by13으로 줄어 든다. \n",
    "```\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "In the videos you looked at how you would improve Fashion MNIST using Convolutions. For your exercise see if you can improve MNIST to 99.8% accuracy or more using only a single convolutional layer and a single MaxPooling 2D. You should stop training once the accuracy goes above this amount. It should happen in less than 20 epochs, so it's ok to hard code the number of epochs for training, but your training must end once it hits the above metric. If it doesn't, then you'll need to redesign your layers.\n",
    "I've started the code for you -- you need to finish it!\n",
    "When 99.8% accuracy has been hit, you should print out the string \"Reached 99.8% accuracy so cancelling training!\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_mnist_conv\n",
    "def train_mnist_conv():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE STARTS HERE\n",
    "    class Mycallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs ={}):\n",
    "            if logs.get('accuracy') >= 0.998:\n",
    "                tf.keras.models.stop_training= True\n",
    "    callbacks = Mycallback()\n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (training_images, training_labels), (test_images, test_labels) = mnist.load_data(path=path)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    training_images = training_images / 255.0\n",
    "    test_images = test_images/ 255.0\n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "            # YOUR CODE STARTS HERE\n",
    "\n",
    "            # YOUR CODE ENDS HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    # model fitting\n",
    "    history = model.fit(\n",
    "        # YOUR CODE STARTS HERE\n",
    "\n",
    "        # YOUR CODE ENDS HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['acc'][-1]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
